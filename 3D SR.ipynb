{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import lib and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import nibabel\n",
    "import imageio\n",
    "from scipy import misc, ndimage\n",
    "from skimage import io, exposure, img_as_uint\n",
    "from sklearn.model_selection import KFold\n",
    "from srmodel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npydir = '/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/512_patch'\n",
    "if not os.path.exists(npydir):\n",
    "    os.makedirs(npydir)\n",
    "\n",
    "patchdir = '/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/128_patch'\n",
    "if not os.path.exists(patchdir):\n",
    "    os.makedirs(patchdir)\n",
    "    \n",
    "testdir = '/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/nii'\n",
    "if not os.path.exists(testdir):\n",
    "    os.makedirs(testdir)\n",
    "    \n",
    "modeldir = '/home/raynard/Documents/models/3DUnetCNN-master/model/'\n",
    "if not os.path.exists(modeldir):\n",
    "    os.makedirs(modeldir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice nii.gz files in Z direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/orig/*.nii.gz\")\n",
    "count = 0\n",
    "for filepath in orig_files:\n",
    "    file = nibabel.load(filepath).get_data().transpose(1, 0, 2)\n",
    "    z = file.shape[2]\n",
    "    n_patch = z//33\n",
    "    j = 0\n",
    "    for i in range(n_patch):\n",
    "        patch = file[:,:,j:j+32]\n",
    "        patch = patch.astype(np.int16)\n",
    "        print(patch.shape)\n",
    "        filename_ = filepath.split('/')[-1].split('.')[0]\n",
    "        filename = filename_ + str(i) + '_OP.npy'\n",
    "        file1 = os.path.join(npydir, filename)\n",
    "        np.save(file1, patch)\n",
    "        count += 1\n",
    "        j += 33\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice nii.gz files in X-Y direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/512_patch/*_OP.npy\")\n",
    "for filepath in op_files:\n",
    "    patch = np.load(filepath)\n",
    "    x = np.split(patch, 4, axis = 0)\n",
    "    a = np.split(x[0], 4, axis = 1)\n",
    "    b = np.split(x[1], 4, axis = 1)\n",
    "    c = np.split(x[2], 4, axis = 1)\n",
    "    d = np.split(x[3], 4, axis = 1)\n",
    "    \n",
    "    for i in range(4):\n",
    "        filename_ = filepath.split('/')[-1].split('OP.')[0]\n",
    "        filename = filename_ + 'a{}_patch.npy'.format(i)\n",
    "        path = os.path.join(patchdir, filename)\n",
    "        np.save(path, a[i])\n",
    "        \n",
    "    for i in range(4):\n",
    "        filename_ = filepath.split('/')[-1].split('OP.')[0]\n",
    "        filename = filename_ + 'b{}_patch.npy'.format(i)\n",
    "        path = os.path.join(patchdir, filename)\n",
    "        np.save(path, b[i])\n",
    "        \n",
    "    for i in range(4):\n",
    "        filename_ = filepath.split('/')[-1].split('OP.')[0]\n",
    "        filename = filename_ + 'c{}_patch.npy'.format(i)\n",
    "        path = os.path.join(patchdir, filename)\n",
    "        np.save(path, c[i])\n",
    "        \n",
    "    for i in range(4):\n",
    "        filename_ = filepath.split('/')[-1].split('OP.')[0]\n",
    "        filename = filename_ + 'd{}_patch.npy'.format(i)\n",
    "        path = os.path.join(patchdir, filename)\n",
    "        np.save(path, d[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check CT patches in nii.gz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/128_patch/*patch.npy\")\n",
    "for filepath in patch_files:\n",
    "    patch = np.load(filepath)\n",
    "    \n",
    "    filename_ = filepath.split('/')[-1].split('.')[0]\n",
    "    og_file = filename_.split('_CT')[0]\n",
    "    filename = filename_ + '.nii.gz'\n",
    "    file1 = os.path.join(testdir, filename)\n",
    "    \n",
    "    orig = nibabel.load('/home/raynard/Documents/models/3DUnetCNN-master/data/orig/{}_CT.nii.gz'.format(og_file))\n",
    "    header = orig.header.copy()\n",
    "    patch = np.transpose(patch, (1,0,2))\n",
    "    patch = nibabel.nifti1.Nifti1Image(patch, None, header = header)\n",
    "    patch.to_filename(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/128_patch/*patch.npy\")\n",
    "for filepath in patch_files:\n",
    "    patch = np.load(filepath)\n",
    "    train_patch = patch[:,:,1::2]\n",
    "    filename_ = filepath.split('/')[-1].split('patch.')[0]\n",
    "    filename = filename_ + 'train.npy'\n",
    "    path = os.path.join(patchdir, filename)\n",
    "    np.save(path, train_patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check training data in nii.gz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/128_patch/*train.npy\")\n",
    "for filepath in train_files:\n",
    "    patch = np.load(filepath)\n",
    "    \n",
    "    filename_ = filepath.split('/')[-1].split('.')[0]\n",
    "    og_file = filename_.split('_CT')[0]\n",
    "    filename = filename_ + '.nii.gz'\n",
    "    file1 = os.path.join(testdir, filename)\n",
    "    \n",
    "    orig = nibabel.load('/home/raynard/Documents/models/3DUnetCNN-master/data/orig/{}_CT.nii.gz'.format(og_file))\n",
    "    header = orig.header.copy()\n",
    "    patch = np.transpose(patch, (1,0,2))\n",
    "    patch = nibabel.nifti1.Nifti1Image(patch, None, header = header)\n",
    "    patch.to_filename(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(path):\n",
    "    lr_img = np.load(path)\n",
    "    lr_img = lr_img.astype(np.float64)\n",
    "    lr_img = np.reshape(lr_img, lr_img.shape + (1,))\n",
    "    return(lr_img)\n",
    "\n",
    "def get_output(path):\n",
    "    img_id = path.replace('train','patch')\n",
    "    hr_img = np.load(img_id)\n",
    "    hr_img = hr_img.astype(np.float64)\n",
    "    hr_img = np.reshape(hr_img, hr_img.shape + (1,))\n",
    "    return(hr_img)\n",
    "\n",
    "def data_generator(files, batch_size = 4):\n",
    "    while True:\n",
    "        batch_paths = np.random.choice(a = files, \n",
    "                                         size = batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = [] \n",
    "        for input_path in batch_paths:\n",
    "            input = get_input(input_path )\n",
    "            output = get_output(input_path)\n",
    "            batch_input += [ input ]\n",
    "            batch_output += [ output ]\n",
    "        \n",
    "        batch_x = np.array( batch_input )\n",
    "        batch_y = np.array( batch_output )\n",
    "        yield( batch_x, batch_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model.summary()\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = glob.glob('/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/128_patch/*train.npy')\n",
    "data.sort()\n",
    "data = np.asarray(data)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42) \n",
    "kf.get_n_splits(data) \n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    if i == 0:\n",
    "        print(\"Training Fold:\", i)\n",
    "        x_train, x_test = data[train_index], data[test_index]\n",
    "        train_gen = data_generator(x_train, batch_size = 2)\n",
    "        val_gen = data_generator(x_test, batch_size = 2)\n",
    "        model = None\n",
    "        model = unet()\n",
    "        model = load_model(modeldir + 'unet_CV_{}.hdf5'.format(i))\n",
    "        model_checkpoint = ModelCheckpoint(modeldir + 'unet_CV_{}.hdf5'.format(i), monitor='val_loss',verbose=1, save_best_only=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, verbose=1,\n",
    "                                      patience=5, min_lr=1e-6)\n",
    "        model.fit_generator(train_gen, steps_per_epoch=4000, epochs=10, verbose =1, callbacks=[model_checkpoint, reduce_lr], validation_data=val_gen, validation_steps=1000, shuffle=True)\n",
    "        i += 1\n",
    "    else:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = glob.glob('/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/128_patch/*train.npy')\n",
    "data.sort()\n",
    "data = np.asarray(data)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42) \n",
    "kf.get_n_splits(data) \n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    if i == 1:\n",
    "        print(\"Training Fold:\", i)\n",
    "        x_train, x_test = data[train_index], data[test_index]\n",
    "        train_gen = data_generator(x_train, batch_size = 2)\n",
    "        val_gen = data_generator(x_test, batch_size = 2)\n",
    "        model = None\n",
    "        model = unet()\n",
    "        model = load_model(modeldir + 'unet_CV_{}.hdf5'.format(i))\n",
    "        model_checkpoint = ModelCheckpoint(modeldir + 'unet_CV_{}.hdf5'.format(i), monitor='val_loss',verbose=1, save_best_only=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, verbose=1,\n",
    "                                      patience=5, min_lr=1e-6)\n",
    "        model.fit_generator(train_gen, steps_per_epoch=4000, epochs=10, verbose =1, callbacks=[model_checkpoint, reduce_lr], validation_data=val_gen, validation_steps=1000, shuffle=True)\n",
    "        i += 1\n",
    "    else:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob.glob('/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/128_patch/*train.npy')\n",
    "data.sort()\n",
    "data = np.asarray(data)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42) \n",
    "kf.get_n_splits(data) \n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    if i == 2:\n",
    "        print(\"Training Fold:\", i)\n",
    "        x_train, x_test = data[train_index], data[test_index]\n",
    "        train_gen = data_generator(x_train, batch_size = 2)\n",
    "        val_gen = data_generator(x_test, batch_size = 2)\n",
    "        model = None\n",
    "        model = unet()\n",
    "        model = load_model(modeldir + 'unet_CV_{}.hdf5'.format(i))\n",
    "        model_checkpoint = ModelCheckpoint(modeldir + 'unet_CV_{}.hdf5'.format(i), monitor='val_loss',verbose=1, save_best_only=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, verbose=1,\n",
    "                                      patience=5, min_lr=1e-6)\n",
    "        model.fit_generator(train_gen, steps_per_epoch=4000, epochs=10, verbose =1, callbacks=[model_checkpoint, reduce_lr], validation_data=val_gen, validation_steps=1000, shuffle=True)\n",
    "        i += 1\n",
    "    else:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob.glob('/home/raynard/Documents/models/3DUnetCNN-master/data/CT_Patches/128_patch/*train.npy')\n",
    "data.sort()\n",
    "data = np.asarray(data)\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42) \n",
    "kf.get_n_splits(data) \n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    if i == 3:\n",
    "        print(\"Training Fold:\", i)\n",
    "        x_train, x_test = data[train_index], data[test_index]\n",
    "        train_gen = data_generator(x_train, batch_size = 2)\n",
    "        val_gen = data_generator(x_test, batch_size = 2)\n",
    "        model = None\n",
    "        model = unet()\n",
    "        model = load_model(modeldir + 'unet_CV_{}.hdf5'.format(i))\n",
    "        model_checkpoint = ModelCheckpoint(modeldir + 'unet_CV_{}.hdf5'.format(i), monitor='val_loss',verbose=1, save_best_only=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, verbose=1,\n",
    "                                      patience=5, min_lr=1e-6)\n",
    "        model.fit_generator(train_gen, steps_per_epoch=4000, epochs=10, verbose =1, callbacks=[model_checkpoint, reduce_lr], validation_data=val_gen, validation_steps=1000, shuffle=True)\n",
    "        i += 1\n",
    "    else:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice CT's into individual folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/test/*.nii.gz\")\n",
    "count = 0\n",
    "for filepath in test_files:\n",
    "    filename = filepath.split('/')[-1].split('.')[0]\n",
    "    ct512dir = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/512'.format(filename)\n",
    "    if not os.path.exists(ct512dir):\n",
    "        os.makedirs(ct512dir)\n",
    "    \n",
    "    ct128dir = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/128'.format(filename)\n",
    "    if not os.path.exists(ct128dir):\n",
    "        os.makedirs(ct128dir)\n",
    "    \n",
    "    file = nibabel.load(filepath).get_data().transpose(1, 0, 2)\n",
    "    z = file.shape[2]\n",
    "    n_patch = z//33\n",
    "    j = 0\n",
    "    for i in range(n_patch):\n",
    "        patch = file[:,:,j:j+32]\n",
    "        patch = patch.astype(np.int16)\n",
    "        filename = str(i) + '.npy'\n",
    "        file1 = os.path.join(ct512dir, filename)\n",
    "        np.save(file1, patch)\n",
    "        x = np.split(patch, 4, axis = 0)\n",
    "        a = np.split(x[0], 4, axis = 1)\n",
    "        b = np.split(x[1], 4, axis = 1)\n",
    "        c = np.split(x[2], 4, axis = 1)\n",
    "        d = np.split(x[3], 4, axis = 1)\n",
    "\n",
    "        for i in range(4):\n",
    "            filename_ = filename.split('.')[0]\n",
    "            filename_ = filename_ + '_a{}_ct.npy'.format(i)\n",
    "            path = os.path.join(ct128dir, filename_)\n",
    "            np.save(path, a[i])\n",
    "\n",
    "        for i in range(4):\n",
    "            filename_ = filename.split('.')[0]\n",
    "            filename_ = filename_ + '_b{}_ct.npy'.format(i)\n",
    "            path = os.path.join(ct128dir, filename_)\n",
    "            np.save(path, b[i])\n",
    "\n",
    "        for i in range(4):\n",
    "            filename_ = filename.split('.')[0]\n",
    "            filename_ = filename_ + '_c{}_ct.npy'.format(i)\n",
    "            path = os.path.join(ct128dir, filename_)\n",
    "            np.save(path, c[i])\n",
    "\n",
    "        for i in range(4):\n",
    "            filename_ = filename.split('.')[0]\n",
    "            filename_ = filename_ + '_d{}_ct.npy'.format(i)\n",
    "            path = os.path.join(ct128dir, filename_)\n",
    "            np.save(path, d[i])\n",
    "        count += 1\n",
    "        j += 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/test/*.nii.gz\")\n",
    "\n",
    "model = None\n",
    "model = unet()\n",
    "model = load_model(modeldir + 'unet_CV_0.hdf5')\n",
    "\n",
    "for filepath in test_files:\n",
    "    filename = filepath.split('/')[-1].split('.')[0]\n",
    "    og_file = filename\n",
    "    ct128dir = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/128'.format(filename)\n",
    "    files = glob.glob(ct128dir + \"/*_ct.npy\")\n",
    "    \n",
    "    for path in files:\n",
    "        patch = np.load(path)\n",
    "        \n",
    "        sr_input = patch[:,:,1::2]\n",
    "        sr_input = sr_input.astype(np.float64)\n",
    "        sr_input = np.reshape(sr_input, (1,) + sr_input.shape + (1,)) \n",
    "        sr_patch = model.predict(sr_input)\n",
    "        sr_patch = np.squeeze(sr_patch)\n",
    "        sr_patch = sr_patch.astype(np.int16)\n",
    "        \n",
    "        sr_name = path.split('/')[-1].split('_ct.')[0]\n",
    "        sr_name = sr_name + '_sr.npy'\n",
    "        file2 = os.path.join(ct128dir, sr_name)\n",
    "\n",
    "        np.save(file2, sr_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_ssim, compare_psnr\n",
    "\n",
    "test_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/test/*.nii.gz\")\n",
    "\n",
    "for filepath in test_files:\n",
    "    psnr = 0\n",
    "    ssim = 0\n",
    "    n = 0\n",
    "    filename = filepath.split('/')[-1].split('.')[0]\n",
    "    ct128dir = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/128'.format(filename)\n",
    "    files = glob.glob(ct128dir + \"/*_sr.npy\")\n",
    "    \n",
    "    for path in files:\n",
    "        model_patch = np.load(path)\n",
    "        path_ = path.replace('_sr.npy','_ct.npy')\n",
    "        patch = np.load(path_)\n",
    "        patch_ssim = compare_ssim(patch, model_patch)\n",
    "        patch_psnr = compare_psnr(patch, model_patch)\n",
    "        ssim += patch_ssim\n",
    "        psnr += patch_psnr\n",
    "        n += 1\n",
    "    \n",
    "    avg_psnr = psnr / n\n",
    "    avg_ssim = ssim / n\n",
    "    print(\"{} Average PSNR:\".format(filename), avg_psnr, \"Average SSIM:\", avg_ssim)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/test/*.nii.gz\")\n",
    "\n",
    "for filepath in test_files:\n",
    "    filename = filepath.split('/')[-1].split('.')[0]\n",
    "    ct128dir = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/128'.format(filename)\n",
    "    orig = nibabel.load('/home/raynard/Documents/models/3DUnetCNN-master/data/test/{}.nii.gz'.format(filename))\n",
    "    outfile1 = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/{}_sr.nii.gz'.format(filename, filename)\n",
    "    outfile2 = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/{}.nii.gz'.format(filename, filename)\n",
    "    header = orig.header.copy()\n",
    "    patches = glob.glob(ct128dir + \"/*_sr.npy\")\n",
    "    patches.sort()\n",
    "    layers = len(patches)/16\n",
    "    layers = int(layers)\n",
    "    \n",
    "    layer = []\n",
    "    ct_layer = []\n",
    "    for i in range(layers):\n",
    "        \n",
    "        alist = glob.glob(ct128dir + \"/{}_a*_sr.npy\".format(i))\n",
    "        alist.sort()\n",
    "        a = []\n",
    "        a_ct = []\n",
    "        for path in alist:\n",
    "            patch = np.load(path)\n",
    "            a.append(patch)\n",
    "            path_ = path.replace('_sr.npy','_ct.npy')\n",
    "            patch_ = np.load(path_)\n",
    "            a_ct.append(patch_)\n",
    "        a_all = np.concatenate((a), axis = 1)\n",
    "        a_ct_all = np.concatenate((a_ct), axis = 1)\n",
    "        \n",
    "        blist = glob.glob(ct128dir + \"/{}_b*_sr.npy\".format(i))\n",
    "        blist.sort()\n",
    "        b = []\n",
    "        b_ct = []\n",
    "        for path in blist:\n",
    "            patch = np.load(path)\n",
    "            b.append(patch)\n",
    "            path_ = path.replace('_sr.npy','_ct.npy')\n",
    "            patch_ = np.load(path_)\n",
    "            b_ct.append(patch_)\n",
    "        b_all = np.concatenate((b), axis = 1)\n",
    "        b_ct_all = np.concatenate((b_ct), axis = 1)\n",
    "        \n",
    "        clist = glob.glob(ct128dir + \"/{}_c*_sr.npy\".format(i))\n",
    "        clist.sort()\n",
    "        c = []\n",
    "        c_ct = []\n",
    "        for path in clist:\n",
    "            patch = np.load(path)\n",
    "            c.append(patch)\n",
    "            path_ = path.replace('_sr.npy','_ct.npy')\n",
    "            patch_ = np.load(path_)\n",
    "            c_ct.append(patch_)\n",
    "        c_all = np.concatenate((c), axis = 1)\n",
    "        c_ct_all = np.concatenate((c_ct), axis = 1)\n",
    "        \n",
    "        \n",
    "        dlist = glob.glob(ct128dir + \"/{}_d*_sr.npy\".format(i))\n",
    "        dlist.sort()\n",
    "        d = []\n",
    "        d_ct = []\n",
    "        for path in dlist:\n",
    "            patch = np.load(path)\n",
    "            d.append(patch)\n",
    "            path_ = path.replace('_sr.npy','_ct.npy')\n",
    "            patch_ = np.load(path_)\n",
    "            d_ct.append(patch_)\n",
    "        d_all = np.concatenate((d), axis = 1)\n",
    "        d_ct_all = np.concatenate((d_ct), axis = 1)\n",
    "        \n",
    "        combinedlayer = np.concatenate((a_all, b_all, c_all, d_all), axis = 0)\n",
    "        combinedlayer_ct = np.concatenate((a_ct_all, b_ct_all, c_ct_all, d_ct_all), axis = 0)\n",
    "        \n",
    "        layer.append(combinedlayer)\n",
    "        ct_layer.append(combinedlayer_ct)\n",
    "        \n",
    "    modelct = np.dstack(layer)\n",
    "    ct = np.dstack(ct_layer)\n",
    "    modelct = np.transpose(modelct, (1,0,2))\n",
    "    ct = np.transpose(ct, (1,0,2))\n",
    "    modelct = nibabel.nifti1.Nifti1Image(modelct, None, header = header)\n",
    "    modelct.to_filename(outfile1)\n",
    "    ct = nibabel.nifti1.Nifti1Image(ct, None, header = header)\n",
    "    ct.to_filename(outfile2)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feb08_P1603_CT \n",
      "Odd MSE: 798.647\tEven MSE: 1686.065 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9995 \n",
      "\n",
      "Feb08_P1733_CT \n",
      "Odd MSE: 587.188\tEven MSE: 1485.865 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9996 \n",
      "\n",
      "Feb08_P1633_CT \n",
      "Odd MSE: 601.227\tEven MSE: 1197.430 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9996 \n",
      "\n",
      "Feb08_P1773_CT \n",
      "Odd MSE: 534.009\tEven MSE: 1450.813 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9996 \n",
      "\n",
      "Feb08_P1873_CT \n",
      "Odd MSE: 861.232\tEven MSE: 1775.925 \n",
      "Odd SSIM: 0.9997\tEven SSIM: 0.9995 \n",
      "\n",
      "Feb08_P1643_CT \n",
      "Odd MSE: 836.674\tEven MSE: 1694.996 \n",
      "Odd SSIM: 0.9997\tEven SSIM: 0.9995 \n",
      "\n",
      "Feb08_P1403_CT \n",
      "Odd MSE: 648.018\tEven MSE: 1718.812 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9995 \n",
      "\n",
      "Feb08_P1673_CT \n",
      "Odd MSE: 698.159\tEven MSE: 1409.699 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9996 \n",
      "\n",
      "Feb08_P1783_CT \n",
      "Odd MSE: 840.287\tEven MSE: 1848.491 \n",
      "Odd SSIM: 0.9997\tEven SSIM: 0.9995 \n",
      "\n",
      "Feb08_P1763_CT \n",
      "Odd MSE: 744.308\tEven MSE: 1593.821 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9995 \n",
      "\n",
      "Feb08_P1813_CT \n",
      "Odd MSE: 566.039\tEven MSE: 1257.165 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9996 \n",
      "\n",
      "Feb08_P1723_CT \n",
      "Odd MSE: 587.666\tEven MSE: 1462.011 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9996 \n",
      "\n",
      "Feb08_P1753_CT \n",
      "Odd MSE: 802.667\tEven MSE: 1970.152 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9995 \n",
      "\n",
      "Feb08_P1863_CT \n",
      "Odd MSE: 781.654\tEven MSE: 1633.443 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9995 \n",
      "\n",
      "Feb08_P1693_CT \n",
      "Odd MSE: 652.834\tEven MSE: 1468.269 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9996 \n",
      "\n",
      "Feb08_P1793_CT \n",
      "Odd MSE: 600.696\tEven MSE: 1439.651 \n",
      "Odd SSIM: 0.9998\tEven SSIM: 0.9996 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import compare_ssim, compare_mse\n",
    "\n",
    "test_files = glob.glob(\"/home/raynard/Documents/models/3DUnetCNN-master/data/test/*.nii.gz\")\n",
    "\n",
    "for filepath in test_files:\n",
    "    filename = filepath.split('/')[-1].split('.')[0]\n",
    "    ctpath = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/{}.nii.gz'.format(filename, filename)\n",
    "    outfile = '/home/raynard/Documents/models/3DUnetCNN-master/data/eval/{}/{}_error.nii.gz'.format(filename, filename)\n",
    "    orig = nibabel.load(ctpath).get_data().transpose(1, 0, 2)\n",
    "    modelctpath = ctpath.replace('CT.nii.gz','CT_sr.nii.gz')\n",
    "    model = nibabel.load(modelctpath).get_data().transpose(1, 0, 2)\n",
    "    copy = nibabel.load(ctpath)\n",
    "    header = copy.header.copy()\n",
    "    \n",
    "    orig_odd = orig[:,:,1::2]\n",
    "    orig_even = orig[:,:,::2]\n",
    "    \n",
    "    model_odd = model[:,:,1::2]\n",
    "    model_even = model[:,:,::2]\n",
    "    \n",
    "    odd_mse = compare_mse(orig_odd, model_odd)\n",
    "    even_mse = compare_mse(orig_even, model_even)\n",
    "    \n",
    "    odd_ssim = compare_ssim(orig_odd, model_odd)\n",
    "    even_ssim = compare_ssim(orig_even, model_even)\n",
    "    \n",
    "    error = orig - model\n",
    "    error = np.transpose(error, (1,0,2))\n",
    "    error = nibabel.nifti1.Nifti1Image(error, None, header = header)\n",
    "    error.to_filename(outfile)\n",
    "\n",
    "    print(\"{} \\nOdd MSE: {:07.3f}\\tEven MSE: {:07.3f} \\nOdd SSIM: {:05.4f}\\tEven SSIM: {:05.4f} \\n\".format(filename, odd_mse, even_mse, odd_ssim, even_ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
